===========================================================
                                      .___ __  __   
          _________________  __ __  __| _/|__|/  |_ 
         / ___\_` __ \__  \ |  |  \/ __ | | \\_  __\
        / /_/  >  | \// __ \|  |  / /_/ | |  ||  |  
        \___  /|__|  (____  /____/\____ | |__||__|  
       /_____/            \/           \/           
              grep rough audit - static analysis tool
                  v3.5 written by @Wireghoul
=================================[justanotherhacker.com]===
[35m[K/tmp/pytorch-lightning/.circleci/config.yml[m[K[36m[K-[m[K[32m[K96[m[K[36m[K-[m[K       echo "Done waiting. Job status code: $status_code" && \
[35m[K/tmp/pytorch-lightning/.circleci/config.yml[m[K[36m[K:[m[K[32m[K97[m[K[36m[K:[m[K       pod_name=$(kubectl get po -l controller-uid=[01;31m[K`kubectl get job $job_name -o "jsonpath={.metadata.labels.controller-uid}"`[m[K | awk 'match($0,!/NAME/) {print $1}') && \
[35m[K/tmp/pytorch-lightning/.circleci/config.yml[m[K[36m[K-[m[K[32m[K98[m[K[36m[K-[m[K       echo "GKE pod name: $pod_name" && \
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/tests/models/test_hooks.py[m[K[36m[K-[m[K[32m[K685[m[K[36m[K-[m[K)
[35m[K/tmp/pytorch-lightning/tests/models/test_hooks.py[m[K[36m[K:[m[K[32m[K686[m[K[36m[K:[m[Kdef test_trainer_model_hook_system_[01;31m[Keval(tmpdir, batches, verb, noun, dataloader, key)[m[K:
[35m[K/tmp/pytorch-lightning/tests/models/test_hooks.py[m[K[36m[K-[m[K[32m[K687[m[K[36m[K-[m[K    called = []
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/tests/trainer/flags/test_overfit_batches.py[m[K[36m[K-[m[K[32m[K74[m[K[36m[K-[m[K@pytest.mark.parametrize("overfit_batches", [0.11, 4])
[35m[K/tmp/pytorch-lightning/tests/trainer/flags/test_overfit_batches.py[m[K[36m[K:[m[K[32m[K75[m[K[36m[K:[m[Kdef test_overfit_batch_limits_[01;31m[Keval(stage, mode, overfit_batches)[m[K:
[35m[K/tmp/pytorch-lightning/tests/trainer/flags/test_overfit_batches.py[m[K[36m[K-[m[K[32m[K76[m[K[36m[K-[m[K    model = ClassificationModel()
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/docs/source/common/trainer.rst[m[K[36m[K-[m[K[32m[K445[m[K[36m[K-[m[KMight make your system slower, but ensures reproducibility.
[35m[K/tmp/pytorch-lightning/docs/source/common/trainer.rst[m[K[36m[K:[m[K[32m[K446[m[K[36m[K:[m[KAlso sets `[01;31m[K`$HOROVOD_FUSION_THRESHOLD=0`[m[K`.
[35m[K/tmp/pytorch-lightning/docs/source/common/trainer.rst[m[K[36m[K-[m[K[32m[K447[m[K[36m[K-[m[K
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/docs/source/common/child_modules.rst[m[K[36m[K-[m[K[32m[K65[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/docs/source/common/child_modules.rst[m[K[36m[K:[m[K[32m[K66[m[K[36m[K:[m[K        def _shared_[01;31m[Keval(self, batch, batch_idx, prefix)[m[K:
[35m[K/tmp/pytorch-lightning/docs/source/common/child_modules.rst[m[K[36m[K-[m[K[32m[K67[m[K[36m[K-[m[K            x, _ = batch
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/tensorboard.py[m[K[36m[K-[m[K[32m[K65[m[K[36m[K-[m[K            If it is a string then it is used as the run-specific subdirectory name,
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/tensorboard.py[m[K[36m[K:[m[K[32m[K66[m[K[36m[K:[m[K            otherwise `[01;31m[K`'version_${version}'`[m[K` is used.
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/tensorboard.py[m[K[36m[K-[m[K[32m[K67[m[K[36m[K-[m[K        log_graph: Adds the computational graph to tensorboard. This requires that
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/tensorboard.py[m[K[36m[K-[m[K[32m[K124[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/tensorboard.py[m[K[36m[K:[m[K[32m[K125[m[K[36m[K:[m[K        By default, it is named `[01;31m[K`'version_${self.version}'`[m[K` but it can be overridden by passing a string value for the
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/tensorboard.py[m[K[36m[K-[m[K[32m[K126[m[K[36m[K-[m[K        constructor's version parameter instead of ``None`` or an int.
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/csv_logs.py[m[K[36m[K-[m[K[32m[K156[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/csv_logs.py[m[K[36m[K:[m[K[32m[K157[m[K[36m[K:[m[K        By default, it is named `[01;31m[K`'version_${self.version}'`[m[K` but it can be overridden by passing a string value for the
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loggers/csv_logs.py[m[K[36m[K-[m[K[32m[K158[m[K[36m[K-[m[K        constructor's version parameter instead of ``None`` or an int.
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/utilities/argparse.py[m[K[36m[K-[m[K[32m[K117[m[K[36m[K-[m[K                # converting to native types like int/float/bool
[35m[K/tmp/pytorch-lightning/pytorch_lightning/utilities/argparse.py[m[K[36m[K:[m[K[32m[K118[m[K[36m[K:[m[K                val = [01;31m[Keval(val)[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/utilities/argparse.py[m[K[36m[K-[m[K[32m[K119[m[K[36m[K-[m[K            env_args[arg_name] = val
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/saving.py[m[K[36m[K-[m[K[32m[K410[m[K[36m[K-[m[K    try:
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/saving.py[m[K[36m[K:[m[K[32m[K411[m[K[36m[K:[m[K        return ast.literal_[01;31m[Keval(val)[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/saving.py[m[K[36m[K-[m[K[32m[K412[m[K[36m[K-[m[K    except (ValueError, SyntaxError) as err:
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K-[m[K[32m[K163[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K:[m[K[32m[K164[m[K[36m[K:[m[K    def on_validation_model_[01;31m[Keval(self)[m[K -> None:
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K-[m[K[32m[K165[m[K[36m[K-[m[K        """Sets the model to eval during the val loop."""
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K-[m[K[32m[K175[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K:[m[K[32m[K176[m[K[36m[K:[m[K    def on_test_model_[01;31m[Keval(self)[m[K -> None:
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K-[m[K[32m[K177[m[K[36m[K-[m[K        """Sets the model to eval during the test loop."""
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K-[m[K[32m[K179[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K:[m[K[32m[K180[m[K[36m[K:[m[K    def on_predict_model_[01;31m[Keval(self)[m[K -> None:
[35m[K/tmp/pytorch-lightning/pytorch_lightning/core/hooks.py[m[K[36m[K-[m[K[32m[K181[m[K[36m[K-[m[K        """Sets the model to eval during the predict loop."""
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loops/dataloader/evaluation_loop.py[m[K[36m[K-[m[K[32m[K208[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loops/dataloader/evaluation_loop.py[m[K[36m[K:[m[K[32m[K209[m[K[36m[K:[m[K    def _on_evaluation_model_[01;31m[Keval(self)[m[K -> None:
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loops/dataloader/evaluation_loop.py[m[K[36m[K-[m[K[32m[K210[m[K[36m[K-[m[K        """Sets model to eval mode."""
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loops/dataloader/prediction_loop.py[m[K[36m[K-[m[K[32m[K146[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loops/dataloader/prediction_loop.py[m[K[36m[K:[m[K[32m[K147[m[K[36m[K:[m[K    def _on_predict_model_[01;31m[Keval(self)[m[K -> None:
[35m[K/tmp/pytorch-lightning/pytorch_lightning/loops/dataloader/prediction_loop.py[m[K[36m[K-[m[K[32m[K148[m[K[36m[K-[m[K        """Calls ``on_predict_model_eval`` hook."""
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K-[m[K[32m[K2487[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K:[m[K[32m[K2488[m[K[36m[K:[m[K- Added reduce ddp results on [01;31m[Keval ([#2434](https://github.com/PyTorchLightning/pytorch-lightning/pull/2434)[m[K)
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K-[m[K[32m[K2489[m[K[36m[K-[m[K- Added a warning when an `IterableDataset` has `__len__` defined ([#2437](https://github.com/PyTorchLightning/pytorch-lightning/pull/2437))
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K-[m[K[32m[K2492[m[K[36m[K-[m[K
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K:[m[K[32m[K2493[m[K[36m[K:[m[K- Enabled no returns from [01;31m[Keval ([#2446](https://github.com/PyTorchLightning/pytorch-lightning/pull/2446)[m[K)
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K-[m[K[32m[K2494[m[K[36m[K-[m[K
[36m[K##############################################[m[K
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K-[m[K[32m[K2827[m[K[36m[K-[m[K- Remove `.item` which causes sync issues ([#1254](https://github.com/PyTorchLightning/pytorch-lightning/pull/1254))
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K:[m[K[32m[K2828[m[K[36m[K:[m[K- Changed smoothing in TQDM to decrease variability of time remaining between training / [01;31m[Keval ([#1194](https://github.com/PyTorchLightning/pytorch-lightning/pull/1194)[m[K)
[35m[K/tmp/pytorch-lightning/CHANGELOG.md[m[K[36m[K-[m[K[32m[K2829[m[K[36m[K-[m[K- Change default logger to dedicated one ([#1064](https://github.com/PyTorchLightning/pytorch-lightning/pull/1064))
